{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios Pandas DataFrames 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Escribe un programa Pandas para conectarte a la base de datos datafundamentals y carga los pagos como un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful\n",
      "   customernumber checknumber paymentdate    amount\n",
      "0             103    HQ336336  2004-10-19   6066.78\n",
      "1             103    JM555205  2003-06-05  14571.44\n",
      "2             103    OM314933  2004-12-18   1676.14\n",
      "3             112    BO864823  2004-12-17  14191.12\n",
      "4             112     HQ55022  2003-06-06  32641.98\n",
      "5             112    ND748579  2004-08-20  33347.88\n",
      "6             114     GG31455  2003-05-20  45864.03\n",
      "7             114    MA765515  2004-12-15  82261.22\n",
      "8             114    NP603840  2003-05-31   7565.08\n",
      "9             114     NR27552  2004-03-10  44894.74\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "def create_server_connection():\n",
    "    PGHOST = 'ep-delicate-unit-a20wq1eg.eu-central-1.aws.neon.tech'\n",
    "    PGDATABASE = 'cesteves_Netmind'\n",
    "    PGUSER = 'cesteves_Netmind_owner'\n",
    "    PGPASSWORD = 'MHcUeXyBw9W1'\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(database=PGDATABASE, user=PGUSER, password=PGPASSWORD, host=PGHOST, port=5432)\n",
    "        print(\"Database connection successful\")\n",
    "    except psycopg2.Error as err:\n",
    "        print(f\"Error: '{err}'\")\n",
    "\n",
    "    return conn\n",
    "\n",
    "def load_table_as_dataframe(table_name):\n",
    "    conn = create_server_connection()\n",
    "    if conn:\n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Failed to connect to the database.\")\n",
    "        return None\n",
    "\n",
    "# Cargar la tabla \"payments\" como un dataframe\n",
    "payments_df = load_table_as_dataframe(\"payments\")\n",
    "\n",
    "if payments_df is not None:\n",
    "    print(payments_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Escribe un programa Pandas para conectarte a la base de datos datafundamentals y guardar el df de pagos en una tabla nueva. Luego muestra las tablas en la bbdd y comprueba que existe la nueva tabla.\n",
    "\n",
    "**Tip:** Usar sqlalchemy (https://www.sqlalchemy.org/)\n",
    "```\n",
    "# !pip install sqlalchemy\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('db_url')\n",
    "df.sql('table_name',engine)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MetaData.__init__() got multiple values for argument 'schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m new_table_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_payments_table\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m connection:\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mpayments_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_table_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataframe saved to table \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_table_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in the datafundamentals database.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Mostrar las tablas en la base de datos datafundamentals y comprobar si la nueva tabla existe\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/generic.py:2872\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2734\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2735\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2736\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2868\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   2869\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2870\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[0;32m-> 2872\u001b[0m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2873\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2883\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/io/sql.py:708\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m if_exists \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfail\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mif_exists\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not valid for if_exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 708\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame, Series):\n\u001b[1;32m    711\u001b[0m     frame \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mto_frame()\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/io/sql.py:788\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[0;34m(con, schema, meta, is_cursor)\u001b[0m\n\u001b[1;32m    786\u001b[0m con \u001b[38;5;241m=\u001b[39m _engine_builder(con)\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_sqlalchemy_connectable(con):\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSQLDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing URI string without sqlalchemy installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/io/sql.py:1410\u001b[0m, in \u001b[0;36mSQLDatabase.__init__\u001b[0;34m(self, engine, schema, meta)\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m meta:\n\u001b[1;32m   1408\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetaData\n\u001b[0;32m-> 1410\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43mMetaData\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnectable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta \u001b[38;5;241m=\u001b[39m meta\n",
      "\u001b[0;31mTypeError\u001b[0m: MetaData.__init__() got multiple values for argument 'schema'"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def create_server_connection():\n",
    "    PGHOST = 'ep-delicate-unit-a20wq1eg.eu-central-1.aws.neon.tech'\n",
    "    PGDATABASE = 'cesteves_Netmind'\n",
    "    PGUSER = 'cesteves_Netmind_owner'\n",
    "    PGPASSWORD = 'MHcUeXyBw9W1'\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(database=PGDATABASE, user=PGUSER, password=PGPASSWORD, host=PGHOST, port=5432)\n",
    "        print(\"Database connection successful\")\n",
    "    except psycopg2.Error as err:\n",
    "        print(f\"Error: '{err}'\")\n",
    "\n",
    "    return conn\n",
    "\n",
    "def load_table_as_dataframe(table_name):\n",
    "    conn = create_server_connection()\n",
    "    if conn:\n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Failed to connect to the database.\")\n",
    "        return None\n",
    "\n",
    "# Cargar la tabla \"payments\" como un dataframe\n",
    "payments_df = load_table_as_dataframe(\"payments\")\n",
    "\n",
    "if payments_df is not None:\n",
    "    # Crear un motor SQLAlchemy para la base de datos datafundamentals\n",
    "    db_url = 'postgresql://cesteves_Netmind_owner:MHcUeXyBw9W1@ep-delicate-unit-a20wq1eg.eu-central-1.aws.neon.tech/cesteves_Netmind?sslmode=require'\n",
    "    engine = create_engine(db_url)\n",
    "\n",
    "    # Guardar el dataframe en una nueva tabla en la base de datos datafundamentals\n",
    "    new_table_name = 'new_payments_table'\n",
    "    with engine.connect() as connection:\n",
    "        payments_df.to_sql(new_table_name, con=connection, if_exists='replace', index=False)\n",
    "        print(f\"Dataframe saved to table '{new_table_name}' in the datafundamentals database.\")\n",
    "\n",
    "        # Mostrar las tablas en la base de datos datafundamentals y comprobar si la nueva tabla existe\n",
    "        result = connection.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\")\n",
    "        tables = result.fetchall()\n",
    "        print(\"Tables in the datafundamentals database:\")\n",
    "        for table in tables:\n",
    "            print(table[0])\n",
    "        \n",
    "        if new_table_name in [table[0] for table in tables]:\n",
    "            print(f\"The new table '{new_table_name}' exists in the database.\")\n",
    "        else:\n",
    "            print(f\"The new table '{new_table_name}' does not exist in the database.\")\n",
    "else:\n",
    "    print(\"Failed to load the 'payments' table as a dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Escribe un programa Pandas para seleccionar filas donde el valor de la columna \"amount\" sea mayor que 400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     customernumber checknumber paymentdate    amount\n",
      "0               103    HQ336336  2004-10-19   6066.78\n",
      "1               103    JM555205  2003-06-05  14571.44\n",
      "2               103    OM314933  2004-12-18   1676.14\n",
      "3               112    BO864823  2004-12-17  14191.12\n",
      "4               112     HQ55022  2003-06-06  32641.98\n",
      "..              ...         ...         ...       ...\n",
      "254             495    BH167026  2003-12-26  59265.14\n",
      "255             495    FN155234  2004-05-14   6276.60\n",
      "256             496    EU531600  2005-05-25  30253.75\n",
      "257             496    MB342426  2003-07-16  32077.44\n",
      "258             496     MN89921  2004-12-31  52166.00\n",
      "\n",
      "[259 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar filas donde el valor de la columna \"amount\" sea mayor que 400\n",
    "filtered_df = payments_df[payments_df['amount'] > 400]\n",
    "\n",
    "# Mostrar las primeras filas del dataframe filtrado\n",
    "print(filtered_df.head(300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Escribe un programa Pandas para seleccionar solo las columnas \"checknumber\" y \"paymentdate\" del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  checknumber paymentdate\n",
      "0    HQ336336  2004-10-19\n",
      "1    JM555205  2003-06-05\n",
      "2    OM314933  2004-12-18\n",
      "3    BO864823  2004-12-17\n",
      "4     HQ55022  2003-06-06\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar solo las columnas \"checknumber\" y \"paymentdate\"\n",
    "selected_columns_df = payments_df[['checknumber', 'paymentdate']]\n",
    "\n",
    "# Mostrar las primeras filas del dataframe con las columnas seleccionadas\n",
    "print(selected_columns_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Escribe un programa Pandas para definir un MultiIndex (multi-índice: varios índices para cada fila), basados en 2 columnas, para:\n",
    "- acceder a datos específicos mediante él\n",
    "- segmentar el DataFrame en función de los niveles de MultiIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           paymentdate    amount\n",
      "customernumber checknumber                      \n",
      "103            HQ336336     2004-10-19   6066.78\n",
      "               JM555205     2003-06-05  14571.44\n",
      "               OM314933     2004-12-18   1676.14\n",
      "112            BO864823     2004-12-17  14191.12\n",
      "               HQ55022      2003-06-06  32641.98\n",
      "\n",
      "Datos específicos para customerNumber=103 y checkNumber='HQ336336':\n",
      "paymentdate    2004-10-19\n",
      "amount            6066.78\n",
      "Name: (103, HQ336336), dtype: object\n",
      "\n",
      "Segmento del DataFrame para customernumber=103:\n",
      "            paymentdate    amount\n",
      "checknumber                      \n",
      "HQ336336     2004-10-19   6066.78\n",
      "JM555205     2003-06-05  14571.44\n",
      "OM314933     2004-12-18   1676.14\n"
     ]
    }
   ],
   "source": [
    "# Definir un MultiIndex basado en las columnas \"customerNumber\" y \"checkNumber\"\n",
    "multi_index_df = payments_df.set_index(['customernumber', 'checknumber'])\n",
    "\n",
    "# Mostrar las primeras filas del dataframe con el MultiIndex\n",
    "print(multi_index_df.head())\n",
    "\n",
    "# Acceder a datos específicos mediante el MultiIndex\n",
    "specific_data = multi_index_df.loc[(103, 'HQ336336')]\n",
    "print(\"\\nDatos específicos para customerNumber=103 y checkNumber='HQ336336':\")\n",
    "print(specific_data)\n",
    "\n",
    "# Segmentar el DataFrame en función de los niveles de MultiIndex\n",
    "segmented_df = multi_index_df.xs(103, level='customernumber')\n",
    "print(\"\\nSegmento del DataFrame para customernumber=103:\")\n",
    "print(segmented_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Escribe un programa Pandas para seleccionar las primeras tres filas usando iloc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customernumber checknumber paymentdate    amount\n",
      "0             103    HQ336336  2004-10-19   6066.78\n",
      "1             103    JM555205  2003-06-05  14571.44\n",
      "2             103    OM314933  2004-12-18   1676.14\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar las primeras tres filas usando iloc\n",
    "first_three_rows = payments_df.iloc[:3]\n",
    "\n",
    "# Mostrar las primeras tres filas\n",
    "print(first_three_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Escribe un programa Pandas para usar loc para seleccionar filas aplicando una condición dada en 2 columas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customernumber checknumber paymentdate    amount\n",
      "0             103    HQ336336  2004-10-19   6066.78\n",
      "2             103    OM314933  2004-12-18   1676.14\n",
      "3             112    BO864823  2004-12-17  14191.12\n",
      "5             112    ND748579  2004-08-20  33347.88\n",
      "7             114    MA765515  2004-12-15  82261.22\n"
     ]
    }
   ],
   "source": [
    "# Convertir la columna 'paymentdate' a tipo datetime\n",
    "payments_df['paymentdate'] = pd.to_datetime(payments_df['paymentdate'])\n",
    "\n",
    "# Usar loc para seleccionar filas aplicando una condición en 2 columnas\n",
    "filtered_df = payments_df.loc[(payments_df['amount'] > 400) & (payments_df['paymentdate'] > '2004-01-01')]\n",
    "\n",
    "# Mostrar las primeras filas del dataframe filtrado\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Escribe un programa Pandas que utilice loc para cambiar en el valor de ammount de las filas que cumplan con una condición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customernumber checknumber paymentdate    amount\n",
      "0             103    HQ336336  2004-10-19   6066.78\n",
      "1             103    JM555205  2003-06-05  14571.44\n",
      "2             103    OM314933  2004-12-18   1676.14\n",
      "3             112    BO864823  2004-12-17  14191.12\n",
      "4             112     HQ55022  2003-06-06  32641.98\n"
     ]
    }
   ],
   "source": [
    "# Usar loc para cambiar el valor de 'amount' de las filas que cumplan con una condición\n",
    "# Por ejemplo, cambiar el valor de 'amount' a 500 donde 'amount' sea menor que 100\n",
    "payments_df.loc[payments_df['amount'] < 100, 'amount'] = 500\n",
    "\n",
    "# Mostrar las primeras filas del dataframe modificado\n",
    "print(payments_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Escribe un programa Pandas que utilice .loc para dividir un DataFrame en función de las etiquetas de filas y columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  checknumber paymentdate\n",
      "0    HQ336336  2004-10-19\n",
      "1    JM555205  2003-06-05\n",
      "2    OM314933  2004-12-18\n",
      "3    BO864823  2004-12-17\n",
      "4     HQ55022  2003-06-06\n"
     ]
    }
   ],
   "source": [
    "# Usar .loc para dividir un DataFrame en función de las etiquetas de filas y columnas\n",
    "# Por ejemplo, seleccionar filas con índices 0 a 4 y columnas 'checknumber' y 'paymentdate'\n",
    "subset_df = payments_df.loc[0:4, ['checknumber', 'paymentdate']]\n",
    "\n",
    "# Mostrar el subset del dataframe\n",
    "print(subset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Escribe un programa Pandas que utilice .loc para segmentar un DataFrame multi-índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           paymentdate    amount\n",
      "customernumber checknumber                      \n",
      "103            HQ336336     2004-10-19   6066.78\n",
      "               JM555205     2003-06-05  14571.44\n",
      "               OM314933     2004-12-18   1676.14\n",
      "112            BO864823     2004-12-17  14191.12\n",
      "               HQ55022      2003-06-06  32641.98\n",
      "paymentdate    2004-10-19 00:00:00\n",
      "amount                     6066.78\n",
      "Name: (103, HQ336336), dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Definir un MultiIndex basado en las columnas \"customerNumber\" y \"checkNumber\"\n",
    "multi_index_df = payments_df.set_index(['customernumber', 'checknumber'])\n",
    "\n",
    "# Mostrar las primeras filas del dataframe con el MultiIndex\n",
    "print(multi_index_df.head())\n",
    "\n",
    "# Usar .loc para segmentar el DataFrame multi-índice\n",
    "# Por ejemplo, seleccionar datos para customerNumber=103 y checkNumber='HQ336336'\n",
    "segmented_df = multi_index_df.loc[(103, 'HQ336336')]\n",
    "\n",
    "# Mostrar el segmento del dataframe\n",
    "print(segmented_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
